"""MCP markdown splitter - Split large markdown files into smaller documents."""

import os
import re
import shutil
from pathlib import Path
from typing import List, Dict

from md_toc import api as md_toc


def generate_docs(
    input_file: str,
    output_dir: str = "docs",
    url_prefix: str = "https://example.com",
    base_path: str = "/docs",
    max_level: int = 6,
) -> None:
    """
    Split a large markdown file into smaller files and generate TOC with absolute URLs.

    Args:
        input_file: Path to the large markdown file to split
        output_dir: Directory to save the split files (default: "docs")
        url_prefix: URL prefix for absolute links (e.g., "https://example.com")
        base_path: Base path for docs (e.g., "/docs")
        max_level: Maximum header level to split at (1=H1, 2=H2, 3=H3, etc.)

    Raises:
        FileNotFoundError: If input file doesn't exist
        ValueError: If max_level is invalid
    """
    if not os.path.exists(input_file):
        raise FileNotFoundError(f"Input file not found: {input_file}")

    if max_level < 1 or max_level > 6:
        raise ValueError("max_level must be between 1 and 6")

    # Clean up existing docs directory
    if os.path.exists(output_dir):
        shutil.rmtree(output_dir)
        print(f"Cleaned up existing directory: {output_dir}")

    # Ensure output directory exists
    Path(output_dir).mkdir(parents=True, exist_ok=True)

    # Read the input file
    try:
        with open(input_file, "r", encoding="utf-8") as f:
            content = f.read()
    except UnicodeDecodeError as e:
        raise ValueError(f"Unable to read file {input_file}: {e}")

    # Build initial TOC using md_toc
    try:
        toc = md_toc.build_toc(input_file, parser="github")
    except Exception as e:
        raise ValueError(f"Failed to build TOC from {input_file}: {e}")

    # Extract headers from TOC and use them to parse sections
    sections = parse_sections_from_toc(content, toc)

    # Filter sections by header level
    filtered_sections = [s for s in sections if s["header"] and s["level"] <= max_level]

    if not filtered_sections:
        print(f"Warning: No sections found with header level <= {max_level}")
        return

    # Generate individual files for each section
    file_mapping = {}
    for section in filtered_sections:
        if section["header"]:
            filename = generate_filename(section["header"])
            filepath = os.path.join(output_dir, filename)

            # Write section content to file
            try:
                with open(filepath, "w", encoding="utf-8") as f:
                    f.write(section["content"])
            except Exception as e:
                print(f"Warning: Failed to write file {filepath}: {e}")
                continue

            # Store mapping for TOC transformation using anchor from TOC
            anchor = section.get("anchor", generate_anchor_link(section["header"]))
            file_mapping[anchor] = filename

    # Transform TOC with absolute URLs
    transformed_toc = transform_toc_links(toc, file_mapping, url_prefix, base_path)

    # Save the transformed TOC
    toc_path = "llms.txt"
    try:
        with open(toc_path, "w", encoding="utf-8") as f:
            f.write("# Table of Contents\n\n")
            f.write(transformed_toc)
    except Exception as e:
        print(f"Warning: Failed to write TOC file {toc_path}: {e}")

    print(f"Documentation generated successfully!")
    print(f"Files saved to: {output_dir}")
    print(f"TOC saved to: {toc_path}")
    print(
        f"Generated {len(filtered_sections)} files (filtered by max_level={max_level})"
    )


def parse_sections_from_toc(content: str, toc: str) -> List[Dict]:
    """
    Parse markdown content into sections using the TOC generated by md_toc.
    This is more reliable as it uses the same logic as md_toc for finding headers.

    Args:
        content: The full markdown content
        toc: TOC string generated by md_toc.build_toc()

    Returns:
        List of dictionaries with 'header', 'level', 'content', and 'anchor' keys
    """
    # Extract header information from TOC
    headers_info = extract_headers_from_toc(toc)

    if not headers_info:
        return []

    lines = content.split("\n")
    sections = []

    # Find the actual header lines in content
    header_positions = []
    for i, line in enumerate(lines):
        stripped_line = line.strip()
        for header_info in headers_info:
            # Check if this line matches a header from TOC
            header_pattern = r"^#{1,6}\s+" + re.escape(header_info["title"])
            if re.match(header_pattern, stripped_line):
                header_positions.append(
                    {
                        "line_num": i,
                        "header": header_info["title"],
                        "level": header_info["level"],
                        "anchor": header_info["anchor"],
                    }
                )
                break

    # Split content into sections based on header positions
    for i, header_pos in enumerate(header_positions):
        start_line = header_pos["line_num"]

        # Find end line (next header or end of file)
        if i < len(header_positions) - 1:
            end_line = header_positions[i + 1]["line_num"]
        else:
            end_line = len(lines)

        # Extract section content
        section_lines = lines[start_line:end_line]
        section_content = "\n".join(section_lines)

        sections.append(
            {
                "header": header_pos["header"],
                "level": header_pos["level"],
                "content": section_content,
                "anchor": header_pos["anchor"],
            }
        )

    return sections


def extract_headers_from_toc(toc: str) -> List[Dict]:
    """
    Extract header information from TOC string.

    Args:
        toc: TOC string from md_toc.build_toc()

    Returns:
        List of dictionaries with 'title', 'level', and 'anchor' keys
    """
    headers = []

    for line in toc.split("\n"):
        if not line.strip():
            continue

        # Parse TOC line: "  - [Header Title](#anchor-link)"
        # Count leading spaces before the dash to determine level
        match = re.match(r"^(\s*)-\s+\[([^\]]+)\]\((#[^)]+)\)", line)
        if match:
            leading_spaces = len(match.group(1))
            title = match.group(2)
            anchor = match.group(3)

            # Calculate level: no spaces = level 1, 2 spaces = level 2, 4 spaces = level 3, etc.
            level = (leading_spaces // 2) + 1

            headers.append({"title": title, "level": level, "anchor": anchor})

    return headers


def generate_filename(header_text: str) -> str:
    """
    Generate a URL-safe filename from header text.

    This follows similar logic to md_toc's anchor generation but for filenames.

    Args:
        header_text: The header text to convert to filename

    Returns:
        A safe filename with .md extension
    """
    # Convert to lowercase
    filename = header_text.lower()

    # Replace spaces and special characters with hyphens
    filename = re.sub(r"[^\w\s-]", "", filename)
    filename = re.sub(r"[-\s]+", "-", filename)

    # Remove leading/trailing hyphens
    filename = filename.strip("-")

    # Ensure we have something
    if not filename:
        filename = "untitled"

    # Add .md extension
    return f"{filename}.md"


def generate_anchor_link(header_text: str) -> str:
    """
    Generate anchor link from header text using GitHub-style formatting.

    This mimics md_toc's anchor generation logic.

    Args:
        header_text: The header text to convert to anchor

    Returns:
        GitHub-style anchor link starting with #
    """
    # Convert to lowercase
    anchor = header_text.lower()

    # Replace spaces with hyphens
    anchor = re.sub(r"\s+", "-", anchor)

    # Remove special characters except hyphens
    anchor = re.sub(r"[^\w\-]", "", anchor)

    # Remove multiple consecutive hyphens
    anchor = re.sub(r"-+", "-", anchor)

    # Remove leading/trailing hyphens
    anchor = anchor.strip("-")

    return f"#{anchor}"


def transform_toc_links(
    toc: str, file_mapping: Dict[str, str], url_prefix: str, base_path: str
) -> str:
    """
    Transform TOC anchor links to absolute URLs.

    Args:
        toc: Original TOC string with anchor links
        file_mapping: Mapping from anchor links to filenames
        url_prefix: URL prefix (e.g., "https://example.com")
        base_path: Base path for docs (e.g., "/docs")

    Returns:
        Transformed TOC with absolute URLs
    """
    transformed_toc = toc

    # Pattern to match markdown links with anchors
    link_pattern = r"\[([^\]]+)\]\((#[^)]+)\)"

    def replace_link(match):
        link_text = match.group(1)
        anchor = match.group(2)

        if anchor in file_mapping:
            filename = file_mapping[anchor]
            absolute_url = f"{url_prefix.rstrip('/')}{base_path.rstrip('/')}/{filename}"
            return f"[{link_text}]({absolute_url})"

        # If no mapping found, keep original
        return match.group(0)

    transformed_toc = re.sub(link_pattern, replace_link, transformed_toc)

    return transformed_toc
